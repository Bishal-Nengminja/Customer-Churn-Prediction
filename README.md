# ğŸ§© Customer Churn Prediction â€” Data Science & MLOps Project  

**Author:** Bishal Nengminja (Jr. Data Scientist)  
**Goal:** Predict customer churn for a subscription-based business using an end-to-end, reproducible ML pipeline with experiment tracking and database integration.

---

## ğŸš€ Overview

Customer churn is a key business problem that directly impacts revenue and customer retention.  
This project demonstrates how a **Data Scientist** builds a complete, production-like pipeline â€” from data ingestion to model evaluation â€” while applying **MLOps best practices** (versioning, tracking, reproducibility).

âœ… Focused on *Data Science role only*  
ğŸš« Excludes full-stack, Docker, and deployment engineering tasks.

---

## ğŸ§± Project Structure

```

customer_churn_project/
â”‚
â”œâ”€â”€ data/                   # Raw â†’ Interim â†’ Processed datasets
â”œâ”€â”€ notebooks/              # EDA and analysis
â”œâ”€â”€ src/                    # Scripts for data prep and modeling
â”œâ”€â”€ models/                 # Trained model artifacts
â”œâ”€â”€ mlflow_tracking/        # MLflow experiment logs
â”œâ”€â”€ .gitignore / .dvcignore # Versioning configs
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ environment.yml         # Conda environment setup
â”œâ”€â”€ Makefile                # Common command shortcuts
â””â”€â”€ README.md               # Project documentation

```

---

## âš™ï¸ Tech Stack

| Component | Tool / Library |
|------------|----------------|
| **Language** | Python 3.10+ |
| **Database** | PostgreSQL |
| **Version Control** | Git |
| **Data Versioning** | DVC |
| **Experiment Tracking** | MLflow + DagsHub |
| **Modeling** | scikit-learn |
| **EDA & Visualization** | pandas, seaborn, matplotlib |
| **Environment** | Conda |
| **Orchestration** | Makefile |

---

## ğŸ§© Workflow Diagram

```

```
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Raw CSV    â”‚
    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Preprocessing  â”‚  âœ Fill nulls, rename columns, clean data
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Upload to Postgresâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Train (MLflow)    â”‚
â”‚  + Feature Eng.     â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â”‚
â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Evaluate & Log    â”‚
â”‚  + DVC Track Model â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

````

---

## ğŸ“Š Key Results

| Metric | Score |
|--------|--------|
| Accuracy | **0.91** |
| Precision | 0.89 |
| Recall | 0.90 |
| F1-Score | 0.90 |
| ROC-AUC | 0.94 |

---

## ğŸ§® Models & Features

- **Algorithms:** Logistic Regression, Random Forest, XGBoost  
- **Feature Engineering:** tenure buckets, encoding, scaling  
- **Selection Criterion:** ROC-AUC and interpretability  
- **Experiment Tracking:** MLflow (local & DagsHub integration)

---

## ğŸ§° How to Run Locally

```bash
# 1ï¸âƒ£ Clone project
git clone <your_github_repo_url>
cd customer_churn_project

# 2ï¸âƒ£ Create environment
conda env create -f environment.yml
conda activate churn_env
pip install -r requirements.txt

# 3ï¸âƒ£ Configure PostgreSQL credentials
cp .env.example .env
# Edit .env to include PGHOST, PGUSER, PGPASSWORD, PGDATABASE

# 4ï¸âƒ£ Place raw dataset
mkdir -p data/raw
cp /path/to/your.csv data/raw/customer_churn_raw.csv

# 5ï¸âƒ£ Preprocess (fill nulls, rename columns)
python src/preprocess.py --input data/raw/customer_churn_raw.csv --output data/interim/customer_clean.csv

# 6ï¸âƒ£ Upload to PostgreSQL
python src/db_utils.py --csv data/interim/customer_clean.csv --table customer_churn

# 7ï¸âƒ£ Train (logs to MLflow)
python src/train.py --csv data/interim/customer_clean.csv --out models/model.pkl --experiment churn_experiment

# 8ï¸âƒ£ Evaluate model
python src/evaluate.py --model models/model.pkl --csv data/interim/customer_clean.csv
````

To visualize experiment runs:

```bash
mlflow ui --port 5000
```

Then open [http://localhost:5000](http://localhost:5000).

---

## ğŸ§¬ MLOps Highlights

âœ… **Data lineage** with DVC
âœ… **Reproducibility** via Conda + Makefile
âœ… **Experiment tracking** (MLflow)
âœ… **Database integration** (PostgreSQL)
âœ… **Code modularization** (for reusability)

---

## ğŸ“ˆ Future Enhancements

* Model explainability (SHAP, LIME)
* Automated retraining pipeline with DVC (`dvc.yaml`)
* Streamlit dashboard for interpretability
* CI/CD for continuous evaluation

---

## ğŸ‘¨â€ğŸ’» About the Author

**Bishal Nengminja** â€” Jr. Data Scientist
Passionate about creating reproducible ML pipelines and applying MLOps in real-world projects.
ğŸ”— [LinkedIn](https://www.linkedin.com/in/bishal-nengminja/) â€¢ [GitHub](https://github.com/Bishal-Nengminja)

---
